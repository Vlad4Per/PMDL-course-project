{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 84792,
     "databundleVersionId": 9524838,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "from idlelib.pyparse import trans\n",
    "\n",
    "from pyexpat import features\n",
    "\n",
    "from torch.onnx.symbolic_opset9 import permute\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:52:03.442655Z",
     "iopub.execute_input": "2024-09-12T22:52:03.443692Z",
     "iopub.status.idle": "2024-09-12T22:52:03.458976Z",
     "shell.execute_reply.started": "2024-09-12T22:52:03.443645Z",
     "shell.execute_reply": "2024-09-12T22:52:03.457699Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:43:46.481992Z",
     "start_time": "2024-10-27T12:43:46.475555Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": "## 1.1 Data preprocessing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# necessary imports\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom tqdm.notebook import tqdm\n\nfrom torch.utils.tensorboard import SummaryWriter\n\nimport torchvision.transforms as transforms\nfrom torchvision.io import read_image",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-09-12T22:52:03.460416Z",
     "iopub.execute_input": "2024-09-12T22:52:03.460769Z",
     "iopub.status.idle": "2024-09-12T22:52:03.472832Z",
     "shell.execute_reply.started": "2024-09-12T22:52:03.460734Z",
     "shell.execute_reply": "2024-09-12T22:52:03.471690Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:43:46.508798Z",
     "start_time": "2024-10-27T12:43:46.491500Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "def load_img(fname):\n",
    "    \"\"\"\n",
    "    Load an image from file, do transformation (including possible augmentation) and return it as torch.tensor\n",
    "\n",
    "    :param fname: path to jpg image\n",
    "    \"\"\"\n",
    "    img = read_image(fname)\n",
    "    x = img / 255.\n",
    "\n",
    "    # Write your code here\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to a consistent input size\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # 50% chance of flipping\n",
    "        transforms.ColorJitter(brightness=0.1,  # Slight color adjustments\n",
    "                               contrast=0.1,\n",
    "                               saturation=0.1,\n",
    "                               hue=0.05),\n",
    "        transforms.RandomRotation(degrees=5),  # Small rotation to keep natural orientation\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "        transforms.ConvertImageDtype(torch.float32)  # Convert to float32 for model compatibility\n",
    "    ])\n",
    "\n",
    "    return transform(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:52:03.474469Z",
     "iopub.execute_input": "2024-09-12T22:52:03.474841Z",
     "iopub.status.idle": "2024-09-12T22:52:03.491139Z",
     "shell.execute_reply.started": "2024-09-12T22:52:03.474795Z",
     "shell.execute_reply": "2024-09-12T22:52:03.490064Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:43:46.566417Z",
     "start_time": "2024-10-27T12:43:46.559152Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T12:43:46.629051Z",
     "start_time": "2024-10-27T12:43:46.611972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from os import walk\n",
    "\n",
    "decode = {\n",
    "    0: \"1-5\", 1: \"5-10\", 2: \"10-15\", 3: \"15-20\", 4: \"20-25\", 5: \"25-30\", 6: \"30-40\", 7: \"40-50\", 8: \"50-60\", 9: \"60-70\",\n",
    "    10: \"70+\"\n",
    "}\n",
    "encode = {\n",
    "    \"1-5\": 0, \"5-10\": 1, \"10-15\": 2, \"15-20\": 3, \"20-25\": 4, \"25-30\": 5, \"30-40\": 6, \"40-50\": 7, \"50-60\": 8, \"60-70\": 9,\n",
    "    \"70+\": 10\n",
    "}\n",
    "img_path = \"facial-age\"\n",
    "# _id = []\n",
    "# _age = []\n",
    "# dirs_ages = []\n",
    "# for (dirpath, dirnames, filenames) in walk(img_path):\n",
    "#     dirs_ages.extend(dirnames)\n",
    "#     break\n",
    "# for dire in dirs_ages:\n",
    "#     for (dirpath, dirnames, filenames) in walk(img_path + \"/\" + dire):\n",
    "#         _id.extend(list(map(lambda x:dire+\"/\"+x,filenames)))\n",
    "#         if 1<=int(dire)<5:\n",
    "#             _age.extend([\"1-5\" for _ in range(len(filenames))])\n",
    "#         elif 5<=int(dire)<10:\n",
    "#             _age.extend([\"5-10\" for _ in range(len(filenames))])\n",
    "#         elif 10<=int(dire)<15:\n",
    "#             _age.extend([\"10-15\" for _ in range(len(filenames))])\n",
    "#         elif 15<=int(dire)<20:\n",
    "#             _age.extend([\"15-20\" for _ in range(len(filenames))])\n",
    "#         elif 20<=int(dire)<25:\n",
    "#             _age.extend([\"20-25\" for _ in range(len(filenames))])\n",
    "#         elif 25<=int(dire)<30:\n",
    "#             _age.extend([\"25-30\" for _ in range(len(filenames))])\n",
    "#         elif 30<=int(dire)<40:\n",
    "#             _age.extend([\"30-40\" for _ in range(len(filenames))])\n",
    "#         elif 40<=int(dire)<50:\n",
    "#             _age.extend([\"40-50\" for _ in range(len(filenames))])\n",
    "#         elif 50<=int(dire)<60:\n",
    "#             _age.extend([\"50-60\" for _ in range(len(filenames))])\n",
    "#         elif 60<=int(dire)<70:\n",
    "#             _age.extend([\"60-70\" for _ in range(len(filenames))])\n",
    "#         elif 70<=int(dire):\n",
    "#             _age.extend([\"70+\" for _ in range(len(filenames))])\n",
    "#         break\n",
    "# \n",
    "# features_data = {\"ID\": _id, \"Age\": _age}\n",
    "# features = pd.DataFrame(features_data)\n",
    "# features.to_csv(\"data.csv\", index=False)\n",
    "features = pd.read_csv(\"data.csv\")\n",
    "features['Age'] = list(map(lambda x: encode[x], features['Age']))\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T12:43:46.670171Z",
     "start_time": "2024-10-27T12:43:46.665898Z"
    }
   },
   "cell_type": "code",
   "source": "#facial-age",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "#img_path = \"/kaggle/input/pmldl-week-2-dnn-training-with-tracking-tools/archive\"\n",
    "\n",
    "# Image attributes\n",
    "#train_features = pd.read_csv(f\"{img_path}/train.csv\")\n",
    "\n",
    "# Load and transform images \n",
    "images = torch.stack(\n",
    "    [load_img(f\"{img_path}/{item['ID']}\") for _, item in features.iterrows()])\n",
    "\n",
    "# Write your code here\n",
    "# Select label(s) from train_features\n",
    "labels = features.get('Age')\n",
    "# Leave values that only 1 or 0 and convert to float just for simplicity\n",
    "labels = torch.from_numpy(labels.to_numpy()).float()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:52:03.493677Z",
     "iopub.execute_input": "2024-09-12T22:52:03.494068Z",
     "iopub.status.idle": "2024-09-12T22:54:19.124245Z",
     "shell.execute_reply.started": "2024-09-12T22:52:03.494029Z",
     "shell.execute_reply": "2024-09-12T22:54:19.122976Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:45:51.065695Z",
     "start_time": "2024-10-27T12:43:46.709119Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": "# Just some checking of shapes\nimages.shape, labels.shape",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:54:19.125711Z",
     "iopub.execute_input": "2024-09-12T22:54:19.126073Z",
     "iopub.status.idle": "2024-09-12T22:54:19.133275Z",
     "shell.execute_reply.started": "2024-09-12T22:54:19.126037Z",
     "shell.execute_reply": "2024-09-12T22:54:19.131823Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:45:51.517056Z",
     "start_time": "2024-10-27T12:45:51.494737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9773, 3, 224, 224]), torch.Size([9773]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": "## 1.3 Data loaders creation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "processed_dataset = TensorDataset(images, labels)\n",
    "\n",
    "# Write your code here\n",
    "# Set proportion and split dataset into train and validation parts\n",
    "proportion = 0.9\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    processed_dataset,\n",
    "    [int(len(images) * 0.7) + 1, int(len(images) * 0.15) + 1, int(len(images) * 0.15)],\n",
    ")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:54:19.624878Z",
     "iopub.execute_input": "2024-09-12T22:54:19.625288Z",
     "iopub.status.idle": "2024-09-12T22:54:19.632823Z",
     "shell.execute_reply.started": "2024-09-12T22:54:19.625244Z",
     "shell.execute_reply": "2024-09-12T22:54:19.631485Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:45:51.630159Z",
     "start_time": "2024-10-27T12:45:51.594518Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": "# Create Dataloaders for training and validation \n# Dataloader is iterable object over dataset\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:54:19.634680Z",
     "iopub.execute_input": "2024-09-12T22:54:19.635046Z",
     "iopub.status.idle": "2024-09-12T22:54:20.031783Z",
     "shell.execute_reply.started": "2024-09-12T22:54:19.635009Z",
     "shell.execute_reply": "2024-09-12T22:54:20.030633Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:45:51.717754Z",
     "start_time": "2024-10-27T12:45:51.694550Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Training\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class CNNClassificationModel(nn.Module):\n",
    "#     \"\"\"\n",
    "#     MLP (multi-layer perceptron) based classification model for MNIST\n",
    "#     \"\"\"\n",
    "# \n",
    "#     def __init__(self, num_classes=20):\n",
    "#         super(CNNClassificationModel, self).__init__()\n",
    "# \n",
    "#         # Add fully connected layers to nn.Sequential to create MLP\n",
    "#         # First layer should take 28x28 vector\n",
    "#         # last layer should return vector of size num_classes\n",
    "#         # do not forget to add activation function between layers\n",
    "# \n",
    "#         self.block1 = nn.Sequential(\n",
    "#             nn.BatchNorm2d(3),\n",
    "#             nn.Conv2d(3, 4, kernel_size=(3, 3), stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(4),\n",
    "#         )\n",
    "# \n",
    "#         self.block2 = nn.Sequential(\n",
    "#             nn.Conv2d(4, 8, kernel_size=(3, 3)),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(8),\n",
    "#         )\n",
    "# \n",
    "#         self.out = nn.Sequential(\n",
    "#             nn.Linear(95048, 1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(1024, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.4),\n",
    "#             nn.Linear(32, num_classes),\n",
    "#         )\n",
    "# \n",
    "#     def forward(self, x):\n",
    "#         x = self.block1(x)\n",
    "#         x = self.block2(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.out(x)\n",
    "#         return x\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:58:12.262937Z",
     "iopub.execute_input": "2024-09-12T22:58:12.263487Z",
     "iopub.status.idle": "2024-09-12T22:58:12.274631Z",
     "shell.execute_reply.started": "2024-09-12T22:58:12.263441Z",
     "shell.execute_reply": "2024-09-12T22:58:12.273197Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:45:51.778590Z",
     "start_time": "2024-10-27T12:45:51.768871Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T12:45:51.850823Z",
     "start_time": "2024-10-27T12:45:51.832451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class CNNClassificationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN-based classification model for age prediction with 20 classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=11):  # Changed to 20 classes\n",
    "        super(CNNClassificationModel, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Fully connected layers with reduced complexity\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "def train(\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        writer=None,\n",
    "        epochs=1,\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        ckpt_path=\"best.pt\",\n",
    "):\n",
    "    # best score for checkpointing\n",
    "    best = 0.51\n",
    "\n",
    "    # iterating over epochs\n",
    "    for epoch in range(epochs):\n",
    "        # training loop description\n",
    "        train_loop = tqdm(\n",
    "            enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch}\"\n",
    "        )\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        # iterate over dataset \n",
    "        for data in train_loop:\n",
    "            # Write your code here\n",
    "            # Move data to a device, do forward pass and loss calculation, do backward pass and run optimizer\n",
    "            id, (inputs, labels) = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.type(torch.int64)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_loop.set_postfix({\"loss\": loss.item()})\n",
    "        # write loss to tensorboard\n",
    "        if writer:\n",
    "            writer.add_scalar(\"Loss/train\", train_loss / len(train_loader), epoch)\n",
    "\n",
    "        # Validation\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()  # evaluation mode\n",
    "            val_loop = tqdm(enumerate(val_loader, 0), total=len(val_loader), desc=\"Val\")\n",
    "            for data in val_loop:\n",
    "                id, (inputs, labels) = data\n",
    "\n",
    "                # Write your code here\n",
    "                # Get predictions and compare them with labels\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.type(torch.int64)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "\n",
    "                for i, j in zip(predicted, labels):\n",
    "                    if i == j: correct += 1\n",
    "\n",
    "                val_loop.set_postfix({\"acc\": correct / total})\n",
    "\n",
    "            if correct / total > best:\n",
    "                torch.save(model.state_dict(), ckpt_path)\n",
    "                best = correct / total\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:54:20.046643Z",
     "iopub.execute_input": "2024-09-12T22:54:20.047140Z",
     "iopub.status.idle": "2024-09-12T22:54:20.060442Z",
     "shell.execute_reply.started": "2024-09-12T22:54:20.047086Z",
     "shell.execute_reply": "2024-09-12T22:54:20.059190Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:45:51.921310Z",
     "start_time": "2024-10-27T12:45:51.898724Z"
    }
   },
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": "## 2.3 Combining everything together",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Write your code here\n",
    "# Pick optimizer from torch.optim and loss function loss_fn from torch.nn that suits best the model\n",
    "# SummaryWriter is used by tensorboard and could be set None\n",
    "model = CNNClassificationModel()\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    optimizer=optim.Adam(model.parameters(), lr=0.001),\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device='cpu',\n",
    "    writer=SummaryWriter(),\n",
    "    epochs=30\n",
    ")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T22:58:17.164571Z",
     "iopub.execute_input": "2024-09-12T22:58:17.165023Z",
     "iopub.status.idle": "2024-09-12T23:07:28.870641Z",
     "shell.execute_reply.started": "2024-09-12T22:58:17.164981Z",
     "shell.execute_reply": "2024-09-12T23:07:28.869202Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:46:04.293385Z",
     "start_time": "2024-10-27T12:45:52.035245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 0:   0%|          | 0/107 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c81927fe665f4b3db8ee9e102d33f2e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 8\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Write your code here\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Pick optimizer from torch.optim and loss function loss_fn from torch.nn that suits best the model\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# SummaryWriter is used by tensorboard and could be set None\u001B[39;00m\n\u001B[0;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m CNNClassificationModel()\n\u001B[1;32m----> 8\u001B[0m train(\n\u001B[0;32m      9\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     10\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m),\n\u001B[0;32m     11\u001B[0m     loss_fn\u001B[38;5;241m=\u001B[39mnn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss(),\n\u001B[0;32m     12\u001B[0m     train_loader\u001B[38;5;241m=\u001B[39mtrain_loader,\n\u001B[0;32m     13\u001B[0m     val_loader\u001B[38;5;241m=\u001B[39mval_loader,\n\u001B[0;32m     14\u001B[0m     device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     15\u001B[0m     writer\u001B[38;5;241m=\u001B[39mSummaryWriter(),\n\u001B[0;32m     16\u001B[0m     epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m\n\u001B[0;32m     17\u001B[0m )\n",
      "Cell \u001B[1;32mIn[28], line 31\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, optimizer, loss_fn, train_loader, val_loader, writer, epochs, device, ckpt_path)\u001B[0m\n\u001B[0;32m     29\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     30\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 31\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[0;32m     32\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mtype(torch\u001B[38;5;241m.\u001B[39mint64)\n\u001B[0;32m     33\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs, labels)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[27], line 53\u001B[0m, in \u001B[0;36mCNNClassificationModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 53\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblock1(x)\n\u001B[0;32m     54\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblock2(x)\n\u001B[0;32m     55\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblock3(x)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:104\u001B[0m, in \u001B[0;36mReLU.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28minput\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minplace)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\functional.py:1500\u001B[0m, in \u001B[0;36mrelu\u001B[1;34m(input, inplace)\u001B[0m\n\u001B[0;32m   1498\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu_(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m   1499\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1500\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": "## 2.4 Inference\nHere you need to perform inference of trained model on test data. \n\nLoad the best checkpoint from training to the model and run inference",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# load best checkpoint to model\nmodel = CNNClassificationModel()\nckpt = torch.load(\"best.pt\")\nmodel.load_state_dict(ckpt)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T23:09:50.760106Z",
     "iopub.execute_input": "2024-09-12T23:09:50.760621Z",
     "iopub.status.idle": "2024-09-12T23:09:51.279987Z",
     "shell.execute_reply.started": "2024-09-12T23:09:50.760577Z",
     "shell.execute_reply": "2024-09-12T23:09:51.278837Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:46:06.167078Z",
     "start_time": "2024-10-27T12:46:06.133262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "import PIL.Image\n",
    "\n",
    "\n",
    "def predict(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Run model inference on test data\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # evaluation mode\n",
    "        test_loop = tqdm(enumerate(test_loader, 0), total=len(test_loader), desc=\"Test\")\n",
    "\n",
    "        for inputs in test_loop:\n",
    "            # Write your code here\n",
    "            # Similar to validation part in training cell\n",
    "            id, pred = inputs\n",
    "            pred = pred.to(device)\n",
    "            _, predicted = torch.max(model(pred).data, 1)\n",
    "\n",
    "            # Extend overall predictions by prediction for a batch\n",
    "            predictions.extend([i.item() for i in predicted])\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def load_training_img(fname):\n",
    "    rgba_image = PIL.Image.open(fname)\n",
    "    rgb_image = rgba_image.convert('RGB')\n",
    "    img = rgb_image\n",
    "\n",
    "    # Write your code here\n",
    "    transform = transforms.Compose([\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.Lambda(lambda x: x/255),\n",
    "        transforms.ConvertImageDtype(torch.float32),\n",
    "        transforms.Resize((224, 224)),  # Resize to a consistent input size\n",
    "        transforms.RandomHorizontalFlip(p=0.5),  # 50% chance of flipping\n",
    "        transforms.ColorJitter(brightness=0.1,  # Slight color adjustments\n",
    "                               contrast=0.1,\n",
    "                               saturation=0.1,\n",
    "                               hue=0.05),\n",
    "        transforms.RandomRotation(degrees=5),  # Small rotation to keep natural orientation\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "        transforms.ConvertImageDtype(torch.float32)\n",
    "    ])  # Convert to float32 for model compatibility\n",
    "    transforms.ToPILImage()(transform(img)).show()\n",
    "\n",
    "    return transform(img)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T23:09:53.088663Z",
     "iopub.execute_input": "2024-09-12T23:09:53.089148Z",
     "iopub.status.idle": "2024-09-12T23:09:53.098352Z",
     "shell.execute_reply.started": "2024-09-12T23:09:53.089102Z",
     "shell.execute_reply": "2024-09-12T23:09:53.097085Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:46:07.642055Z",
     "start_time": "2024-10-27T12:46:07.634478Z"
    }
   },
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# process test data and run inference on it\n",
    "images = torch.stack(\n",
    "    [load_training_img(\"1410.png\")])\n",
    "\n",
    "test_loader = DataLoader(images, batch_size=batch_size, shuffle=False)\n",
    "predictions = predict(model, test_loader, device='cpu')\n",
    "\n",
    "print(f\"Predicted age for the person on the picture: {decode[predictions[0]]}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-12T23:10:41.451022Z",
     "iopub.execute_input": "2024-09-12T23:10:41.451486Z",
     "iopub.status.idle": "2024-09-12T23:10:50.886004Z",
     "shell.execute_reply.started": "2024-09-12T23:10:41.451446Z",
     "shell.execute_reply": "2024-09-12T23:10:50.884850Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T12:51:13.208966Z",
     "start_time": "2024-10-27T12:51:13.113031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2966fba654a643b49112d8e234c0c435"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted age for the person on the picture: 50-60\n"
     ]
    }
   ],
   "execution_count": 54
  }
 ]
}
